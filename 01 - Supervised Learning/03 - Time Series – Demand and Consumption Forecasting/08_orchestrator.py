#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
==============================================================================
TIME SERIES FORECASTING - PIPELINE ORCHESTRATOR (CORRECTED)
==============================================================================

Purpose: Execute complete end-to-end time series forecasting pipeline

This corrected version properly checks all outputs generated by each script.

Author: Bruno Silva (Corrected)
Date: 2025
==============================================================================
"""

import os
import subprocess
import sys
import shutil
import time
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Tuple, Optional

# Try to import colorama for colored output
try:
    from colorama import Fore, Style, init
    init(autoreset=True)
    COLORS_AVAILABLE = True
except ImportError:
    COLORS_AVAILABLE = False

    class Fore:
        RED = GREEN = BLUE = YELLOW = CYAN = MAGENTA = RESET = ""

    class Style:
        BRIGHT = RESET_ALL = ""


# ==============================================================================
# CONFIGURATION
# ==============================================================================

class Config:
    """Orchestrator configuration parameters."""
    # Pipeline scripts
    SCRIPTS = [
        "01_exploratory_analysis.py",
        "02_preprocessing.py",
        "03_train_models.py",
        "04_evaluate_metrics.py",
        "05_plot_predicted_vs_actual.py",
        "06_residual_analysis.py",
        "07_final_report.py"
    ]

    SCRIPT_NAMES = [
        "Exploratory Data Analysis",
        "Data Preprocessing & Feature Engineering",
        "Time Series Model Training",
        "Metrics Evaluation & Comparison",
        "Forecast Visualization",
        "Residual Diagnostic Analysis",
        "Final Report Generation"
    ]

    SCRIPT_DESCRIPTIONS = [
        "Stationarity testing, decomposition, ACF/PACF analysis",
        "Calendar features, lag features, rolling stats, temporal split",
        "ARIMA, SARIMA, Holt-Winters, Prophet models",
        "RMSE, MAE, MAPE metrics comparison",
        "Best model predictions vs. actual values",
        "Distribution, autocorrelation, Q-Q plots",
        "Comprehensive Markdown report with insights"
    ]

    # File and directory paths
    LOG_FILE = "pipeline_execution.log"
    INPUT_VOLTAGE = "inputs/voltagem_bateria.csv"
    INPUT_MISSIONS = "inputs/missoes_diarias.csv"
    OUTPUT_DIR = Path("outputs")

    # Output subdirectories
    DATA_PROCESSED_DIR = OUTPUT_DIR / "data_processed"
    MODELS_DIR = OUTPUT_DIR / "models"
    PREDICTIONS_DIR = OUTPUT_DIR / "predictions"
    GRAPHICS_DIR = OUTPUT_DIR / "graphics"

    # Key output files
    VOLTAGE_METRICS = OUTPUT_DIR / "voltage_metrics_comparison.csv"
    MISSIONS_METRICS = OUTPUT_DIR / "missions_metrics_comparison.csv"
    FINAL_REPORT = OUTPUT_DIR / "FINAL_REPORT.md"

    # Expected outputs per step - CORRECTED to match actual script outputs
    EXPECTED_OUTPUTS = {
        0: {  # EDA - 01_exploratory_analysis.py
            "critical": [
                GRAPHICS_DIR,  # Directory must be created
            ],
            "files": [
                GRAPHICS_DIR / "voltage_timeseries.png",
                GRAPHICS_DIR / "voltage_decomposition.png",
                GRAPHICS_DIR / "voltage_acf.png",
                GRAPHICS_DIR / "voltage_pacf.png",
                GRAPHICS_DIR / "missions_timeseries.png",
                GRAPHICS_DIR / "missions_decomposition.png",
                GRAPHICS_DIR / "missions_acf.png",
                GRAPHICS_DIR / "missions_pacf.png"
            ]
        },
        1: {  # Preprocessing - 02_preprocessing.py
            "critical": [
                DATA_PROCESSED_DIR / "voltage",
                DATA_PROCESSED_DIR / "missions"
            ],
            "files": [
                # Voltage dataset
                DATA_PROCESSED_DIR / "voltage" / "X_train_scaled.pkl",
                DATA_PROCESSED_DIR / "voltage" / "X_test_scaled.pkl",
                DATA_PROCESSED_DIR / "voltage" / "y_train.pkl",
                DATA_PROCESSED_DIR / "voltage" / "y_test.pkl",
                DATA_PROCESSED_DIR / "voltage" / "scaler.pkl",
                DATA_PROCESSED_DIR / "voltage" / "feature_names.pkl",
                # Missions dataset
                DATA_PROCESSED_DIR / "missions" / "X_train_scaled.pkl",
                DATA_PROCESSED_DIR / "missions" / "X_test_scaled.pkl",
                DATA_PROCESSED_DIR / "missions" / "y_train.pkl",
                DATA_PROCESSED_DIR / "missions" / "y_test.pkl",
                DATA_PROCESSED_DIR / "missions" / "scaler.pkl",
                DATA_PROCESSED_DIR / "missions" / "feature_names.pkl"
            ]
        },
        2: {  # Model training - 03_train_models.py
            "critical": [
                MODELS_DIR / "voltage",
                MODELS_DIR / "missions",
                PREDICTIONS_DIR / "voltage",
                PREDICTIONS_DIR / "missions"
            ],
            "files": [
                # Training summaries
                MODELS_DIR / "voltage" / "training_summary.pkl",
                MODELS_DIR / "missions" / "training_summary.pkl",
                # At minimum, naive baseline predictions
                PREDICTIONS_DIR / "voltage" / "naive_baseline_predictions.pkl",
                PREDICTIONS_DIR / "missions" / "naive_baseline_predictions.pkl"
            ]
        },
        3: {  # Metrics evaluation - 04_evaluate_metrics.py
            "critical": [],
            "files": [
                OUTPUT_DIR / "voltage_metrics_comparison.csv",
                OUTPUT_DIR / "voltage_metrics_comparison.md",
                OUTPUT_DIR / "missions_metrics_comparison.csv",
                OUTPUT_DIR / "missions_metrics_comparison.md"
            ]
        },
        4: {  # Visualization - 05_plot_predicted_vs_actual.py
            "critical": [],
            "files": [
                GRAPHICS_DIR / "voltage_best_model_forecast.png",
                GRAPHICS_DIR / "voltage_best_model_forecast.pdf",
                GRAPHICS_DIR / "missions_best_model_forecast.png",
                GRAPHICS_DIR / "missions_best_model_forecast.pdf"
            ]
        },
        5: {  # Residual analysis - 06_residual_analysis.py
            "critical": [],
            "files": [
                GRAPHICS_DIR / "voltage_residual_analysis.png",
                GRAPHICS_DIR / "missions_residual_analysis.png"
            ]
        },
        6: {  # Final report - 07_final_report.py
            "critical": [],
            "files": [
                FINAL_REPORT
            ]
        }
    }

    # Required libraries
    REQUIRED_LIBRARIES = [
        'pandas', 'numpy', 'sklearn', 'matplotlib',
        'seaborn', 'scipy', 'statsmodels'
    ]

    # Execution settings
    SCRIPT_TIMEOUT = 1800  # 30 minutes


# ==============================================================================
# UTILITY FUNCTIONS
# ==============================================================================

def log(message: str, level: str = "INFO") -> None:
    """Write message to log file with timestamp."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {level}: {message}\n"
    with open(Config.LOG_FILE, 'a', encoding='utf-8') as f:
        f.write(log_entry)


def print_colored(
        message: str,
        color: str = Fore.RESET,
        bright: bool = False) -> None:
    """Print colored message if colorama available."""
    if COLORS_AVAILABLE:
        style = Style.BRIGHT if bright else ""
        print(f"{style}{color}{message}{Style.RESET_ALL}")
    else:
        print(message)


def print_header(title: str) -> None:
    """Print formatted header."""
    print()
    print_colored("=" * 80, Fore.CYAN, bright=True)
    print_colored(title.center(80), Fore.CYAN, bright=True)
    print_colored("=" * 80, Fore.CYAN, bright=True)
    print()


def print_separator() -> None:
    """Print separator line."""
    print_colored("â”€" * 80, Fore.CYAN)


# ==============================================================================
# DEPENDENCY CHECKING
# ==============================================================================

def check_dependencies() -> bool:
    """Check if required dependencies are installed."""
    print_header("CHECKING DEPENDENCIES")
    log("Starting dependency check")

    missing = []
    for lib in Config.REQUIRED_LIBRARIES:
        try:
            __import__(lib)
            print_colored(f"  âœ“ {lib}", Fore.GREEN)
        except ImportError:
            print_colored(f"  âœ— {lib} - NOT FOUND", Fore.RED)
            missing.append(lib)

    if missing:
        print()
        print_colored(
            f"âš ï¸  Missing libraries: {
                ', '.join(missing)}",
            Fore.YELLOW,
            bright=True)
        print_colored(
            f"Install with: pip install {
                ' '.join(missing)}",
            Fore.YELLOW)
        log(f"Missing libraries: {missing}", "WARNING")
        return False

    print()
    print_colored("âœ“ All dependencies installed", Fore.GREEN, bright=True)
    log("All dependencies OK")
    return True


def check_input_data() -> bool:
    """Check if input data exists."""
    print_header("CHECKING INPUT DATA")
    log("Checking input data")

    input_files = [
        (Config.INPUT_VOLTAGE, "Battery voltage data (voltagem_bateria.csv)"),
        (Config.INPUT_MISSIONS, "Daily missions data (missoes_diarias.csv)")
    ]

    all_found = True
    for file_path, description in input_files:
        if Path(file_path).exists():
            print_colored(f"âœ“ Found: {description}", Fore.GREEN)
            size_mb = Path(file_path).stat().st_size / (1024 * 1024)
            print_colored(f"  File: {file_path}", Fore.CYAN)
            print_colored(f"  Size: {size_mb:.2f} MB", Fore.CYAN)
            log(f"Found input dataset: {file_path}")
        else:
            print_colored(f"âœ— Missing: {description}", Fore.RED)
            print_colored(f"  Expected at: {file_path}", Fore.YELLOW)
            log(f"Missing: {description} at {file_path}", "ERROR")
            all_found = False

    if not all_found:
        print()
        print_colored("âš ï¸  Input data not found!", Fore.RED, bright=True)
        print("\nOptions:")
        print("  [1] Continue anyway (data might be already processed)")
        print("  [2] Abort")

        choice = input("\nChoose option: ").strip()
        if choice == '1':
            print_colored(
                "âš ï¸  Continuing without input verification",
                Fore.YELLOW)
            log("Continued without input verification", "WARNING")
            return True
        else:
            print_colored("Execution aborted", Fore.RED)
            log("Execution aborted due to missing input data")
            return False

    return True


# ==============================================================================
# OUTPUT VERIFICATION
# ==============================================================================

def verify_outputs(step_index: int) -> Tuple[bool, List[str]]:
    """
    Verify expected outputs were created.

    Returns:
        Tuple[bool, List[str]]: (all_critical_exist, list_of_missing_files)
    """
    if step_index not in Config.EXPECTED_OUTPUTS:
        return True, []

    print()
    print_colored("Verifying outputs...", Fore.CYAN)

    outputs = Config.EXPECTED_OUTPUTS[step_index]
    critical = outputs.get("critical", [])
    files = outputs.get("files", [])

    missing_critical = []
    missing_files = []

    # Check critical directories/files
    if critical:
        print_colored("  Critical outputs:", Fore.CYAN)
        for output in critical:
            path = Path(output)
            if path.exists():
                if path.is_dir():
                    num_files = sum(1 for _ in path.rglob('*') if _.is_file())
                    print_colored(
                        f"    âœ“ {path}/ ({num_files} files)", Fore.GREEN)
                else:
                    size_kb = path.stat().st_size / 1024
                    print_colored(
                        f"    âœ“ {path} ({
                            size_kb:.1f} KB)",
                        Fore.GREEN)
            else:
                print_colored(f"    âœ— {path} - NOT FOUND", Fore.RED)
                missing_critical.append(str(path))
                log(f"Critical output not found: {path}", "ERROR")

    # Check expected files
    if files:
        print_colored("  Expected files:", Fore.CYAN)
        for output in files:
            path = Path(output)
            if path.exists():
                if path.is_file():
                    size_kb = path.stat().st_size / 1024
                    if size_kb < 1024:
                        print_colored(
                            f"    âœ“ {
                                path.name} ({
                                size_kb:.1f} KB)",
                            Fore.GREEN)
                    else:
                        size_mb = size_kb / 1024
                        print_colored(
                            f"    âœ“ {
                                path.name} ({
                                size_mb:.2f} MB)",
                            Fore.GREEN)
                else:
                    print_colored(f"    âœ“ {path}/", Fore.GREEN)
            else:
                print_colored(f"    âš ï¸  {path.name} - not found", Fore.YELLOW)
                missing_files.append(str(path))
                log(f"Expected file not found: {path}", "WARNING")

    # Determine success
    all_critical_exist = len(missing_critical) == 0

    if not all_critical_exist:
        print_colored(
            f"\n  âœ— {
                len(missing_critical)} critical outputs missing!",
            Fore.RED,
            bright=True)
    elif missing_files:
        print_colored(
            f"\n  âš ï¸  {
                len(missing_files)} optional files missing",
            Fore.YELLOW)
    else:
        print_colored("\n  âœ“ All outputs verified", Fore.GREEN, bright=True)

    return all_critical_exist, missing_critical + missing_files


# ==============================================================================
# SCRIPT EXECUTION
# ==============================================================================

def execute_script(script_path: str, script_name: str,
                   step_number: int) -> Tuple[bool, float, str, str]:
    """Execute a single script and return success status."""
    print()
    print_separator()
    print_colored(f"â–¶ [{step_number}/{len(Config.SCRIPTS)}] Executing: {script_name}",
                  Fore.BLUE, bright=True)
    print_separator()

    log(f"Executing {script_path}")

    start_time = time.time()

    try:
        result = subprocess.run(
            [sys.executable, script_path],
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            env={**os.environ, "PYTHONUTF8": "1"},
            timeout=Config.SCRIPT_TIMEOUT
        )

        elapsed = time.time() - start_time

        if result.returncode == 0:
            print_colored(f"âœ“ Completed: {script_name} ({elapsed:.2f}s)",
                          Fore.GREEN, bright=True)
            log(f"{script_path} completed successfully ({elapsed:.2f}s)", "SUCCESS")
            return True, elapsed, result.stdout, result.stderr
        else:
            print_colored(f"âœ— Error: {script_name}", Fore.RED, bright=True)
            log(f"{script_path} failed", "ERROR")
            log(f"Error details: {result.stderr}", "ERROR")
            return False, elapsed, result.stdout, result.stderr

    except subprocess.TimeoutExpired:
        print_colored(
            f"âœ— Timeout: {script_name} (exceeded {
                Config.SCRIPT_TIMEOUT //
                60} minutes)",
            Fore.RED,
            bright=True)
        log(f"{script_path} timed out", "ERROR")
        return False, Config.SCRIPT_TIMEOUT, "", "Timeout exceeded"
    except Exception as e:
        print_colored(
            f"âœ— Exception: {script_name} - {str(e)}", Fore.RED, bright=True)
        log(f"{script_path} exception: {str(e)}", "ERROR")
        return False, 0, "", str(e)


def handle_script_error(script_name: str, stdout: str, stderr: str) -> str:
    """Handle script execution error."""
    print()
    print_colored("=" * 80, Fore.RED)
    print_colored(f"ERROR EXECUTING: {script_name}", Fore.RED, bright=True)
    print_colored("=" * 80, Fore.RED)

    print("\nWhat would you like to do?")
    print("  [1] Continue to next script (may cause cascade errors)")
    print("  [2] Retry this script")
    print("  [3] Abort execution")
    print("  [4] Debug mode (show full output)")

    choice = input("\nChoose option: ").strip()

    if choice == '1':
        log("User chose to continue after error", "WARNING")
        return 'continue'
    elif choice == '2':
        log("User chose to retry script")
        return 'retry'
    elif choice == '4':
        print("\n" + "=" * 80)
        print("STDOUT:")
        print("=" * 80)
        print(stdout if stdout else "(empty)")
        print("\n" + "=" * 80)
        print("STDERR:")
        print("=" * 80)
        print(stderr if stderr else "(empty)")
        print("=" * 80)
        return handle_script_error(script_name, stdout, stderr)
    else:
        log("Execution aborted by user after error")
        return 'abort'


# ==============================================================================
# PIPELINE EXECUTION
# ==============================================================================

def run_pipeline(steps_to_run: Optional[List[int]] = None) -> None:
    """Run the complete pipeline or specific steps."""
    if steps_to_run is None:
        steps_to_run = list(range(len(Config.SCRIPTS)))

    print_header("STARTING PIPELINE EXECUTION")
    log("=" * 80)
    log("Pipeline execution started")
    log(f"Steps to run: {[i + 1 for i in steps_to_run]}")

    results = []
    total_time = 0

    for i in steps_to_run:
        script = Config.SCRIPTS[i]
        script_name = Config.SCRIPT_NAMES[i]

        # Check if script exists
        if not Path(script).exists():
            print_colored(f"âš ï¸  Script not found: {script}", Fore.YELLOW)
            log(f"Script not found: {script}", "WARNING")

            cont = input(
                "Continue without this script? (y/n): ").strip().lower()
            if cont == 'y':
                results.append((script_name, False, 0, []))
                continue
            else:
                print_colored("Execution aborted", Fore.RED)
                log("Execution aborted due to missing script")
                print_summary(results, total_time, aborted=True)
                sys.exit(1)

        # Execute script
        while True:
            success, elapsed, stdout, stderr = execute_script(
                script, script_name, i + 1)
            total_time += elapsed

            # Verify outputs
            if success:
                outputs_ok, missing = verify_outputs(i)
                results.append((script_name, outputs_ok, elapsed, missing))

                if not outputs_ok:
                    print()
                    print_colored(
                        "âš ï¸  Warning: Critical outputs missing!",
                        Fore.YELLOW,
                        bright=True)
                    cont = input("Continue anyway? (y/n): ").strip().lower()
                    if cont != 'y':
                        print_colored("Execution aborted", Fore.RED)
                        print_summary(results, total_time, aborted=True)
                        sys.exit(1)

                break
            else:
                results.append((script_name, False, elapsed, []))
                action = handle_script_error(script_name, stdout, stderr)

                if action == 'continue':
                    break
                elif action == 'retry':
                    print_colored("\nRetrying...", Fore.YELLOW)
                    results.pop()  # Remove failed result before retry
                else:
                    print_colored("\nExecution aborted", Fore.RED)
                    log("Execution aborted by user")
                    print_summary(results, total_time, aborted=True)
                    sys.exit(1)

    print_summary(results, total_time)
    log("Pipeline execution completed")
    log(f"Total time: {total_time:.2f}s")


def print_summary(results: List[Tuple[str, bool, float, List[str]]],
                  total_time: float, aborted: bool = False) -> None:
    """Print execution summary."""
    print()
    print_header("EXECUTION SUMMARY")

    successes = sum(1 for _, success, _, _ in results if success)
    failures = len(results) - successes

    if aborted:
        print_colored("âš ï¸  EXECUTION ABORTED", Fore.YELLOW, bright=True)

    print(f"Scripts executed: {len(results)}/{len(Config.SCRIPTS)}")
    print_colored(f"Successes: {successes}", Fore.GREEN)
    if failures > 0:
        print_colored(f"Failures: {failures}", Fore.RED)

    minutes = int(total_time // 60)
    seconds = int(total_time % 60)
    print(f"\nTotal time: {minutes}m {seconds}s")

    print("\nDetailed results:")
    for script_name, success, elapsed, missing in results:
        status = "âœ“" if success else "âœ—"
        color = Fore.GREEN if success else Fore.RED
        print_colored(f"  {status} {script_name} ({elapsed:.2f}s)", color)
        if missing:
            print_colored(f"     Missing outputs: {len(missing)}", Fore.YELLOW)

    print(f"\nFull log: {Config.LOG_FILE}")

    if successes == len(Config.SCRIPTS):
        print()
        print_colored(
            "ðŸŽ‰ PIPELINE COMPLETED SUCCESSFULLY!",
            Fore.GREEN,
            bright=True)
        print_colored(f"ðŸ“„ Final report: {Config.FINAL_REPORT}", Fore.CYAN)

    print_separator()


# ==============================================================================
# MAIN MENU
# ==============================================================================

def show_main_menu() -> str:
    """Show interactive main menu."""
    print_header("TIME SERIES FORECASTING\nML Pipeline Orchestrator")

    print("Select execution mode:")
    print("  [1] Run complete pipeline (all 7 scripts)")
    print("  [2] Run specific steps (choose which ones)")
    print("  [3] Run from step N onwards")
    print("  [4] Clean outputs and restart")
    print("  [5] View pipeline status")
    print("  [6] Exit")

    return input("\nChoose option: ").strip()


def clean_outputs() -> None:
    """Clean all output files and folders."""
    print_header("CLEAN OUTPUTS")

    items_to_clean = [
        Config.OUTPUT_DIR,
        Config.LOG_FILE,
        "__pycache__"
    ]

    print("The following items will be deleted:")
    for item in items_to_clean:
        if Path(item).exists():
            print_colored(f"  â€¢ {item}", Fore.YELLOW)

    print()
    print_colored(
        "âš ï¸  WARNING: This action cannot be undone!",
        Fore.RED,
        bright=True)
    confirm = input("Type 'yes' to confirm: ").strip().lower()

    if confirm == 'yes':
        deleted_count = 0
        for item in items_to_clean:
            path = Path(item)
            try:
                if path.is_dir():
                    shutil.rmtree(path)
                    deleted_count += 1
                elif path.is_file():
                    path.unlink()
                    deleted_count += 1
            except Exception as e:
                print_colored(f"Error deleting {item}: {e}", Fore.RED)

        print_colored(f"\nâœ“ Cleanup completed ({deleted_count} items deleted)",
                      Fore.GREEN, bright=True)
        log("Outputs cleaned by user")
    else:
        print_colored("Cleanup cancelled", Fore.YELLOW)


def view_pipeline_status() -> None:
    """View current pipeline status with detailed file counts."""
    print_header("PIPELINE STATUS")

    print("ðŸ“ Directory Structure:")

    directories = [
        (Path("inputs/"), "Input data"),
        (Config.OUTPUT_DIR, "Main outputs"),
        (Config.DATA_PROCESSED_DIR, "Preprocessed data"),
        (Config.MODELS_DIR, "Trained models"),
        (Config.PREDICTIONS_DIR, "Model predictions"),
        (Config.GRAPHICS_DIR, "Visualizations")
    ]

    for dir_path, description in directories:
        if dir_path.exists() and dir_path.is_dir():
            num_files = sum(1 for _ in dir_path.rglob('*') if _.is_file())
            print_colored(f"  âœ“ {description}: {num_files} files", Fore.GREEN)
        else:
            print_colored(f"  âœ— {description}: not found", Fore.RED)

    print("\nðŸ“Š Key Outputs by Category:")

    # Check each step's outputs
    for step_idx, step_name in enumerate(Config.SCRIPT_NAMES):
        if step_idx in Config.EXPECTED_OUTPUTS:
            outputs = Config.EXPECTED_OUTPUTS[step_idx]
            files = outputs.get("files", [])

            existing = sum(1 for f in files if Path(f).exists())
            total = len(files)

            if existing == total:
                status_color = Fore.GREEN
                status = "âœ“"
            elif existing > 0:
                status_color = Fore.YELLOW
                status = "âš "
            else:
                status_color = Fore.RED
                status = "âœ—"

            print_colored(
                f"  {status} Step {
                    step_idx + 1}: {step_name} ({existing}/{total} files)",
                status_color)

    print(f"\nðŸ“ Log file: {Config.LOG_FILE}")
    if Path(Config.LOG_FILE).exists():
        size_kb = Path(Config.LOG_FILE).stat().st_size / 1024
        print_colored(f"  Size: {size_kb:.1f} KB", Fore.CYAN)


# ==============================================================================
# MAIN FUNCTION
# ==============================================================================

def main() -> None:
    """Main orchestrator function."""
    print_colored("\n" + "=" * 80, Fore.CYAN)
    print_colored(
        "TIME SERIES FORECASTING PIPELINE ORCHESTRATOR".center(80),
        Fore.CYAN,
        bright=True)
    print_colored("=" * 80 + "\n", Fore.CYAN)

    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Pipeline Orchestrator")
    parser.add_argument(
        '--all',
        action='store_true',
        help='Run complete pipeline')
    parser.add_argument(
        '--clean',
        action='store_true',
        help='Clean all outputs')
    parser.add_argument(
        '--status',
        action='store_true',
        help='View pipeline status')
    parser.add_argument(
        '--skip-checks',
        action='store_true',
        help='Skip dependency checks')
    args = parser.parse_args()

    # Handle command line modes
    if args.clean:
        clean_outputs()
        return

    if args.status:
        view_pipeline_status()
        return

    # Check dependencies
    if not args.skip_checks:
        if not check_dependencies():
            print()
            cont = input("Continue anyway? (y/n): ").strip().lower()
            if cont != 'y':
                sys.exit(1)

        if not check_input_data():
            sys.exit(1)

    # Execute pipeline
    if args.all:
        run_pipeline()
    else:
        # Interactive mode
        while True:
            choice = show_main_menu()

            if choice == '1':
                run_pipeline()
                break
            elif choice == '2':
                print("\nEnter step numbers (comma-separated, e.g., 1,3,4):")
                selection = input("Steps: ").strip()
                try:
                    steps = [int(s.strip()) - 1 for s in selection.split(',')]
                    steps = [s for s in steps if 0 <= s < len(Config.SCRIPTS)]
                    if steps:
                        run_pipeline(steps)
                        break
                except BaseException:
                    print_colored("Invalid input", Fore.RED)
            elif choice == '3':
                print("\nEnter starting step number:")
                try:
                    start = int(input("Start from: ").strip()) - 1
                    if 0 <= start < len(Config.SCRIPTS):
                        steps = list(range(start, len(Config.SCRIPTS)))
                        run_pipeline(steps)
                        break
                except BaseException:
                    print_colored("Invalid input", Fore.RED)
            elif choice == '4':
                clean_outputs()
            elif choice == '5':
                view_pipeline_status()
                input("\nPress ENTER to continue...")
            elif choice == '6':
                print_colored("Goodbye! ðŸ‘‹", Fore.CYAN)
                break
            else:
                print_colored("Invalid option", Fore.RED)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print()
        print_colored("\nâš ï¸  Execution interrupted by user", Fore.YELLOW)
        sys.exit(1)
    except Exception as e:
        print_colored(f"\nâœ— Unexpected error: {e}", Fore.RED)
        import traceback
        traceback.print_exc()
        sys.exit(1)
